{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7d302b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c6f23772",
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('/Users/czh/Documents/coding/ml/digit classification/archive')\n",
    "images, labels = mndata.load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c2bd0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def ReLU_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "    x_max = np.max(x, axis=axis, keepdims=True)\n",
    "    e_x = np.exp(x - x_max)\n",
    "    \n",
    "    return e_x / e_x.sum(axis=axis, keepdims=True)\n",
    "\n",
    "def forward_pass(x):\n",
    "    z1 = x @ weights['W1'] + weights['b1']\n",
    "    a1 = ReLU(z1)\n",
    "\n",
    "    z2 = a1 @ weights['W2'] + weights['b2']\n",
    "    a2 = ReLU(z2)\n",
    "\n",
    "    z3 = a2 @ weights['W3'] + weights['b3']\n",
    "    output = softmax(z3)\n",
    "    return z1, a1, z2, a2, z3, output\n",
    "\n",
    "def cross_entropy(predictions, true_label):\n",
    "    epsilon = 1e-10 # small constant to avoid log(0)\n",
    "    return -np.log(predictions[true_label] + epsilon)\n",
    "\n",
    "def he_init(fan_in, fan_out):\n",
    "    return np.random.randn(fan_in, fan_out) * np.sqrt(2.0 / fan_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4162885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(x, true_label, output, z1, a1, z2, a2, z3):\n",
    "    # encode true label\n",
    "    one_hot = np.zeros(10)\n",
    "    one_hot[true_label] = 1\n",
    "    \n",
    "    # Layer 3\n",
    "    dL_dz3 = output - one_hot\n",
    "    dL_dW3 = a2.reshape(-1, 1) @ dL_dz3.reshape(1, -1)\n",
    "    dL_db3 = dL_dz3\n",
    "\n",
    "    # Layer 2\n",
    "    dL_da2 = dL_dz3 @ weights['W3'].T\n",
    "    dL_dz2 = dL_da2 * ReLU_derivative(z2)\n",
    "    dL_dW2 = a1.reshape(-1, 1) @ dL_dz2.reshape(1, -1)\n",
    "    dL_db2 = dL_dz2\n",
    "\n",
    "    # Layer 1\n",
    "    dL_da1 = dL_dz2 @ weights['W2'].T\n",
    "    dL_dz1 = dL_da1 * ReLU_derivative(z1)\n",
    "    dL_dW1 = x.reshape(-1, 1) @ dL_dz1.reshape(1, -1)\n",
    "    dL_db1 = dL_dz1\n",
    "\n",
    "    return dL_dW1, dL_db1, dL_dW2, dL_db2, dL_dW3, dL_db3\n",
    "\n",
    "def update_weights(learning_rate, gradients):\n",
    "    dL_dW1, dL_db1, dL_dW2, dL_db2, dL_dW3, dL_db3 = gradients\n",
    "    \n",
    "    weights['W1'] = weights['W1'] - learning_rate * dL_dW1\n",
    "    weights['b1'] = weights['b1'] - learning_rate * dL_db1\n",
    "    weights['W2'] = weights['W2'] - learning_rate * dL_dW2\n",
    "    weights['b2'] = weights['b2'] - learning_rate * dL_db2\n",
    "    weights['W3'] = weights['W3'] - learning_rate * dL_dW3\n",
    "    weights['b3'] = weights['b3'] - learning_rate * dL_db3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ba6fa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy = 89.92%, Loss = 0.3417\n",
      "Epoch 2: Accuracy = 93.28%, Loss = 0.2322\n",
      "Epoch 3: Accuracy = 93.95%, Loss = 0.2059\n",
      "Epoch 4: Accuracy = 94.43%, Loss = 0.1933\n",
      "Epoch 5: Accuracy = 94.71%, Loss = 0.1822\n",
      "Epoch 6: Accuracy = 94.95%, Loss = 0.1723\n",
      "Epoch 7: Accuracy = 95.18%, Loss = 0.1665\n",
      "Epoch 8: Accuracy = 95.33%, Loss = 0.1602\n",
      "Epoch 9: Accuracy = 95.42%, Loss = 0.1566\n",
      "Epoch 10: Accuracy = 95.59%, Loss = 0.1534\n"
     ]
    }
   ],
   "source": [
    "#init weights\n",
    "\n",
    "weights = {\n",
    "    'W1': he_init(784, 16),\n",
    "    'b1': np.zeros(16),\n",
    "    'W2': he_init(16, 16),\n",
    "    'b2': np.zeros(16),\n",
    "    'W3': he_init(16, 10),\n",
    "    'b3': np.zeros(10)\n",
    "}\n",
    "\n",
    "#training\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for j in range(len(images)):\n",
    "        img = np.array(images[j], dtype=np.float32) / 255.0\n",
    "        label = labels[j]\n",
    "\n",
    "        # forward pass\n",
    "        z1, a1, z2, a2, z3, output = forward_pass(img)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = cross_entropy(output, label)\n",
    "        total_loss += loss\n",
    "\n",
    "        # backward pass\n",
    "        gradients = backward_pass(img, label, output, z1, a1, z2, a2, z3)\n",
    "\n",
    "        # update weights\n",
    "        update_weights(learning_rate, gradients)\n",
    "\n",
    "        # track accuracy\n",
    "        if np.argmax(output) == label:\n",
    "            correct += 1\n",
    "    \n",
    "    # print progress after each epoch\n",
    "    accuracy = (correct / len(images)) * 100\n",
    "    avg_loss = total_loss / len(images)\n",
    "    print(f\"Epoch {i+1}: Accuracy = {accuracy:.2f}%, Loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f3eb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
